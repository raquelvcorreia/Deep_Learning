{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aece2564",
   "metadata": {},
   "source": [
    "# Udemy course: TensorFlow Developer certificate in 2023: Zero to Mastery Section 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4feef-4b63-4ac7-923c-3ff1cf756992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TensorFlow version \n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Add timestamp\n",
    "import datetime\n",
    "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f60030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be using a TensorFlow dataset\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# list of available datasets\n",
    "datasets_list = tfds.list_builders()\n",
    "print(datasets_list[:5], len(datasets_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a dataset and confirm that it exists\n",
    "target_dataset = \"food101\"\n",
    "print(f\"'{target_dataset}' in TensorFlow Datasets: {target_dataset in datasets_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fc537",
   "metadata": {},
   "outputs": [],
   "source": [
    " data_dir = r'C:\\Users\\raque\\Documents\\Udemy-ZTM\\datasets'\n",
    "    \n",
    "(train_data, test_data), ds_info = tfds.load(name=\"food101\", # target dataset to get from TFDS\n",
    "                                             split=[\"train\", \"validation\"], # what splits of data should we get? note: not all datasets have train, valid, test\n",
    "                                             data_dir = data_dir,\n",
    "                                             shuffle_files=True, # shuffle files on download?\n",
    "                                             download = False,\n",
    "                                             as_supervised=True, # download data in tuple format (sample, label), e.g. (image, label)\n",
    "                                             with_info=True) # include dataset metadata? if so, tfds.load() returns tuple (data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cab709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the classes names through dataset_info.features()\n",
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e89f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the clsses names\n",
    "class_names = ds_info.features[\"label\"].names\n",
    "\n",
    "#check the name of the first 10 classes\n",
    "class_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b350b2",
   "metadata": {},
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc44e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample off the training data\n",
    "train_one_sample = train_data.take(1) # samples are in format (image_tensor, label)\n",
    "train_one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89681d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for image, label in train_one_sample:\n",
    "  print(f\"\"\"\n",
    "  Image shape: {image.shape}\n",
    "  Image dtype: {image.dtype}\n",
    "  Target class from Food101 (tensor form): {label}\n",
    "  Class name (str form): {class_names[label.numpy()]}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min and max values in tensors\n",
    "tf.reduce_min(image), tf.reduce_max(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e5635",
   "metadata": {},
   "source": [
    "Not all the images in the dataset have the same shape\n",
    "\n",
    "The images are not scaled with tensor values between 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bffbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image tensor\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.title(class_names[label.numpy()]) # add title to image by indexing on class_names list\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cde1f1",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "Data is int unit8 datatype, data tensors have multiple sizes, the tensors are not scaled/normalized\n",
    "\n",
    "create a preprocess_img() that will convert the datasets into a format that is ready to use in modeling:\n",
    "\n",
    "* Convert datatype to float32 -  using tf.cast()\n",
    "* reshape tensors so that all have the same size: (224,224,3) -  using tf.image.resize()\n",
    "* nomalize the values to tht there are between 0 & 1 - by deviding tensor by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cbde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(image, label, img_shape=224):\n",
    "    \"\"\"\n",
    "    Converts image datatype from 'uint8' -> 'float32' and reshapes image to\n",
    "    [img_shape, img_shape, color_channels]\n",
    "    \"\"\"\n",
    "    image = tf.image.resize(image, [img_shape, img_shape]) # reshape to img_shape\n",
    "    return tf.cast(image, tf.float32), label # return (float32_image, label) tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess one sample image and check the outputs\n",
    "preprocessed_img = preprocess_img(image, label)[0]\n",
    "print(f\"\"\"Image before preprocessing:\\n {image[:2]}...,\\nShape: {image.shape},\\nDatatype: {image.dtype}\\n\"\"\")\n",
    "print(f\"\"\"Image after preprocessing:\\n {preprocessed_img[:2]}...,\\nShape: {preprocessed_img.shape},\\nDatatype: {preprocessed_img.dtype}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7965080",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(preprocessed_img/255.) # for imshow the image/tensor has to be scaled/normalized\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b564005",
   "metadata": {},
   "source": [
    "## Batch & prepare the dataset\n",
    "\n",
    "* create batches (computing on batchs is memory efficient)\n",
    "\n",
    "Convert image tensors and lables into batches of 32 image, label pairs - use metrhods from tf.data\n",
    "\n",
    "\n",
    "Process:\n",
    "Original dataset (e.g. train_data) -> map() -> shuffle() -> batch() -> prefetch() -> PrefetchDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map preprocessing function to training data (and paralellize)\n",
    "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Shuffle train_data and turn it into batches and prefetch it\n",
    "# Prefetch allows later elements to be prepared while the current element is being\n",
    "# processed. This often improves latency and throughput, at the cost of\n",
    "# using additional memory to store prefetched elements.\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Map prepreprocessing function to test data\n",
    "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Turn test data into batches shuffling is not needed\n",
    "test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe5d5bf",
   "metadata": {},
   "source": [
    "# Create modelling callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ModelCheckpoint callback to save model's progress\n",
    "checkpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                      monitor=\"val_accuracy\", # save the model weights with best validation accuracy\n",
    "                                                      save_best_only=True, # only save the best weights\n",
    "                                                      save_weights_only=True, # only save model weights (not whole model)\n",
    "                                                      verbose=0) # don't print out whether or not model is being saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfcabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed precision training\n",
    "# Uses a mix of float16 and float32 tensors to make better use of your GPU's memory.\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(policy=\"mixed_float16\") # set global policy to mixed precision\n",
    "mixed_precision.global_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c2e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build feature extraction model\n",
    "# Base model: EfficientNetB0\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Create base model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False) # exclude top layer this will be replaced by a new output layer appropriate for what is being modeled\n",
    "base_model.trainable = False # freeze base model layers\n",
    "\n",
    "# Create Functional model\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "# Note: EfficientNetBX models have rescaling built-in\n",
    "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
    "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
    "x = layers.Dense(len(class_names))(x) # want one output neuron per class\n",
    "# Separate activation of output layer so we can output float32 activations\n",
    "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot as is the case for this dataset\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6081b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a6d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dtype_policy attributes of layers in our model\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35405d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the layers in the base model and see what dtype policy they're using\n",
    "for layer in model.layers[1].layers[:20]: # checking only the first 20 layes\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the feature extraction model\n",
    "\n",
    "# create tensorboard callback\n",
    "import datetime\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  \"\"\"\n",
    "  Creates a TensorBoard callback instance to store log files.\n",
    "\n",
    "  Stores log files with the filepath:\n",
    "    \"dir_name/experiment_name/current_datetime/\"\n",
    "\n",
    "  Args:\n",
    "    dir_name: target directory to store TensorBoard log files\n",
    "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
    "  \"\"\"\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback\n",
    "\n",
    "# Turn off all warnings except for errors\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Fit the model with callbacks\n",
    "history_101_food_classes_feature_extract = model.fit(train_data,\n",
    "                                                     epochs=3,\n",
    "                                                     steps_per_epoch=len(train_data),\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=int(0.15 * len(test_data)),\n",
    "                                                     callbacks=[create_tensorboard_callback(\"training_logs\",\n",
    "                                                                                            \"efficientnetb0_101_classes_all_data_feature_extract\"),\n",
    "                                                                model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a696c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eef5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fec73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d54e603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1644491556872720054\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5f5e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62e0043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  4 19:48:46 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.78       Driver Version: 512.78       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   59C    P8    10W /  N/A |    859MiB /  6144MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     10228    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10792    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     11312    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11336    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11668    C+G   ...210.91\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     12816    C+G   ...eek\\PowerToys.Peek.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     13216    C+G   ...\\PowerToys.FancyZones.exe    N/A      |\n",
      "|    0   N/A  N/A     15512    C+G   ... Host\\Razer Synapse 3.exe    N/A      |\n",
      "|    0   N/A  N/A     16080    C+G   ....0.26.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A     20724    C+G   ...\\atom\\app-1.60.0\\atom.exe    N/A      |\n",
      "|    0   N/A  N/A     29064    C+G   ...3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     31544    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     32988    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     46112    C+G   ...rmouryCrateKeyControl.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9504923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of GPUs: 0\n",
      "GPU 0: NVIDIA GeForce RTX 2060 with Max-Q Design (UUID: GPU-b0ed3f09-207a-7b3a-831b-75a343906131)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of GPUs: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdca8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d95b20d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print('Please install GPU version of TF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "# Evaluate model on the  whole test dataset (only 15% was used during training)\n",
    "results_feature_extract_model = model.evaluate(test_data)\n",
    "results_feature_extract_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9a68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038afc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the validation and training data separately\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "\n",
    "  Args:\n",
    "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
    "  \"\"\"\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  # Plot accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdae0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_101_food_classes_feature_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and evaluate checkpoint weights\n",
    "\n",
    "# Create a function to recreate the original model\n",
    "def create_model():\n",
    "  # Create base model\n",
    "  input_shape = (224, 224, 3)\n",
    "  base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False)\n",
    "  base_model.trainable = False # freeze base model layers\n",
    "\n",
    "  # Create Functional model\n",
    "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "  # Note: EfficientNetBX models have rescaling built-in \n",
    "  x = base_model(inputs, training=False) # set base_model to inference mode only\n",
    "  x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
    "  x = layers.Dense(len(class_names))(x) # want one output neuron per class\n",
    "  # Separate activation of output layer so we can output float32 activations\n",
    "  outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "  return model\n",
    "\n",
    "# Create and compile a new version of the original model (new weights)\n",
    "created_model = create_model()\n",
    "created_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                      optimizer=tf.keras.optimizers.Adam(),\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "# Load the saved weights\n",
    "created_model.load_weights(checkpoint_path)\n",
    "\n",
    "# Evaluate the model with loaded weights\n",
    "results_created_model_with_loaded_weights = created_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "assert np.isclose(results_feature_extract_model, results_created_model_with_loaded_weights).all(), \"Loaded weights results are not close to original model.\"  # check if all elements in array are close\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3a821",
   "metadata": {},
   "source": [
    "## Save the whole model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model locally\n",
    "save_dir = \"07_efficientnetb0_feature_extract_model_mixed_precision\"\n",
    "model.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9886ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model previously saved above\n",
    "loaded_saved_model = tf.keras.models.load_model(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1420ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check loaded model performance\n",
    "results_loaded_saved_model = loaded_saved_model.evaluate(test_data)\n",
    "results_loaded_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4250b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "assert np.isclose(results_feature_extract_model, results_loaded_saved_model).all() # results variables  had to be instatiated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1dc9d",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in loaded_saved_model.layers:\n",
    "    layer.trainable = True # set all layers to trainable\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n",
    "                                                  patience=3) # if val loss does not decreases for 3 epochs in a row, stop training\n",
    "\n",
    "# Create ModelCheckpoint callback to save best model during fine-tuning\n",
    "checkpoint_path = \"fine_tune_checkpoints/\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                      save_best_only=True,\n",
    "                                                      monitor=\"val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating learning rate reduction callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1, # print out when learning rate goes down\n",
    "                                                 min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "loaded_saved_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                        optimizer=tf.keras.optimizers.Adam(0.0001), # 10x lower learning rate than the default\n",
    "                        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ee55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start to fine-tune (all layers)\n",
    "history_101_food_classes_all_data_fine_tune = loaded_saved_model.fit(train_data,\n",
    "                                                        epochs=100, # fine-tune for a maximum of 100 epochs\n",
    "                                                        steps_per_epoch=len(train_data),\n",
    "                                                        validation_data=test_data,\n",
    "                                                        validation_steps=int(0.15 * len(test_data)), # validation during training on 15% of test data\n",
    "                                                        callbacks=[create_tensorboard_callback(\"training_logs\", \"efficientb0_101_classes_all_data_fine_tuning\"), # track the model training logs\n",
    "                                                                   model_checkpoint, # save only the best model during training\n",
    "                                                                   early_stopping, # stop model after X epochs of no improvements\n",
    "                                                                   reduce_lr]) # reduce the learning rate after X epochs of no improvements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d53351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
